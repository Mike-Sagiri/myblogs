---
layout: post
title: CUDA与Pytorch在现代Windows（含WSL）中的显存管理
date: 2025-11-10 10:23 +0800
categories: [技术经验, pytorch]
tags: [cuda, pytorch] # TAG 名称应始终为小写
mermaid: true
---

如果你观察过任务管理器的GPU页面，你就会发现，除了专用GPU内存（也就是显存）外，还有共享GPU内存。默认的大小是内存的一半，它们共同构成了总GPU内存。那么，共享GPU内存与专用GPU内存是什么关系？cuda与pytorch如何使用它们？

## 专用GPU内存与共享GPU内存
在你的任务管理器的GPU页面，会显示你的专用GPU内存和共享GPU内存。其中，专用GPU内存就是我们常说的显存。而共享GPU内存，则是Windows的一大特性：[WDDM](https://learn.microsoft.com/zh-cn/windows-hardware/drivers/display/windows-vista-display-driver-model-design-guide){: target="_blank"}
WDDM与其他的组件共同允许GPU，在不经过CPU的情况下，直接访问内存。这部分内存就是共享GPU内存。它提高了GPU的内存访问效率，尽管仍然不如显存，但是在显存如此金贵的当下，它为小显存的显卡提供了一条增大显存的方式——加装内存条，因为共享GPU内存是内存的一半。

![alt text](assets/img/gpu-vram/gpu_memory.png)
_两种显存_

> 暂时没能发现调整共享GPU内存的方法
{: .prompt-warning }

## CUDA对两种GPU内存的管理
在现代Windows和Nvidia驱动中，对显存的分配默认会将共享GPU内存考虑在内。当专用GPU内存分配满后，就会接着分配共享GPU内存。

> 但是暂未测试老的GPU驱动，是否无法利用共享GPU内存。
{: .prompt-warning }

比如，在cuda c++中，直接使用`cudaMalloc`函数，会优先使用专用GPU内存，当专用GPU内存分配满后，则会分配共享GPU内存。当二者都满，才会报错`outofmemory`。
而如果使用`cudaMallocHost`函数，则会在内存中分配不分页的内存。*不分页*可以理解为这部分内存不会被放到速度缓慢的虚拟内存（硬盘）中，同时会允许GPU直接访问，而不通过CPU。在任务管理器里，这部分内存就会被显示为共享GPU内存。

```cuda
//参考cuda c++代码，使用nvcc xxx.cpp -o xxx.exe编译，需要环境变量中有visual studio的cl.exe编译器
#include <stdio.h>
#include <cuda_runtime.h>
#include <iostream>

int main() {
    float* d_data;
    size_t bytes = 1024*1024*1024 * sizeof(int);
    cudaError_t err = cudaMalloc(&d_data, bytes);
    printf("%s\n", cudaGetErrorString(err));
    std::cin.get();
    cudaFree(d_data);
    cudaError_t err2 = cudaMallocHost(&d_data, bytes);
    printf("%s\n", cudaGetErrorString(err));
    std::cin.get();
    cudaFreeHost(d_data);
    return 0;
}
```

1. **使用cudaMalloc分配专用GPU内存的情况**
![alt text](assets/img/gpu-vram/delicated_gpu_ram.png)
_使用`cudaMalloc`分配专用GPU内存的情况_

2. **使用`cudaMallocHost`分配共享GPU内存的情况，此时内存占用也会增加**
![alt text](assets/img/gpu-vram/shared_gpu_ram.png)
_使用`cudaMallocHost`分配共享GPU内存的情况，此时内存占用也会增加_

3. **使用`cudaMalloc`分配总GPU内存的情况，在专用GPU内存分配满后，接着分配了共享GPU内存**
![alt text](assets/img/gpu-vram/total_gpu_ram.png)
_使用`cudaMalloc`分配总GPU内存的情况，在专用GPU内存分配满后，接着分配了共享GPU内存_

4. **使用`cudaMalloc`分配总GPU内存的情况，此时需要分配的数量超过了总GPU内存，因此分配失败**
![alt text](assets/img/gpu-vram/total_gpu_ram_failed.png)
_使用`cudaMalloc`分配总GPU内存的情况，此时需要分配的数量超过了总GPU内存，因此分配失败_

## Pytorch 对两种显存的利用
因为pytorch事实上也是调用的CUDA的接口来实现显存分配的，因此pytorch的行为与CUDA是高度一致的。具体如下：

### **Dataloader的`pin_memory=True`**
`pin_memory=True`指示Dataloader分配共享GPU内存来加载数据集。这样既可以不占用宝贵的专用GPU内存，又可以让GPU快速地读取数据，并且不经过CPU。否则，将直接分配到普通内存里。  

```python
import torch
import time
from torch.utils.data import Dataset, DataLoader

# 1. 创建一个假的“数据集”，它不从磁盘读，只是在RAM中生成数据
# 这样我们可以排除磁盘I/O的瓶颈，专注于内存行为
class FakeDataset(Dataset):
    def __init__(self, num_samples=200):
        self.num_samples = num_samples
        # 每个“样本”是 50MB 的随机数据 (50 * 1024 * 1024) / 4 = 13,107,200 个元素
        self.data = torch.randn(num_samples, 13107200) 
        print(f"在 CPU RAM 中创建了一个 {self.data.nbytes / 1024**2:.2f} MB 的“数据集”")

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.data[idx]

if __name__ == '__main__':
    # 确保 CUDA 可用，虽然这个实验主要在 CPU 和 锁页内存 上
    print(f"CUDA a可用: {torch.cuda.is_available()}")

    dataset = FakeDataset()

    # 2. 配置 DataLoader
    # num_workers > 0 会启动子进程
    # pin_memory=True 是关键！
    loader = DataLoader(
        dataset,
        batch_size=32,      # 每个批次 32 * 50MB = 1.6GB
        num_workers=8,      # 使用 8 个CPU核心来加载
        pin_memory=True,    # ！！！指示 DataLoader 将数据“钉”在锁页内存中
        prefetch_factor=2   # 每个 worker 预取 2 个批次
    )

    print("\n--- 开始实验 ---")
    print("DataLoader 已启动。")
    print("请立即打开 [任务管理器] -> [性能] -> [GPU]")
    print("观察 [共享 GPU 内存] (Shared GPU Memory) 的使用情况。")
    print("它应该会显著上升！")
    
    # 3. 循环迭代，模拟训练
    try:
        # 我们只迭代一小部分，然后暂停，让您有时间观察
        for i, data_batch in enumerate(loader):
            print(f"加载了第 {i+1} 批数据...")
            
            # 在一个真实的训练循环中，您会在这里把数据移到GPU
            # data_batch = data_batch.to('cuda', non_blocking=True)
            # ...然后执行模型前向传播...
            
            time.sleep(0.5) # 减慢循环，以便观察内存
            
            if i > 20:
                print("\n已加载超过20个批次。")
                print("现在 [共享 GPU 内存] 应该已经很高了。")
                print("脚本将暂停 60 秒，请尽情观察任务管理器。")
                time.sleep(60)
                print("演示结束。")
                break
                
    except KeyboardInterrupt:
        print("\n用户停止了实验。")
    except Exception as e:
        print(f"\n发生错误: {e}")
```
![alt text](assets/img/gpu-vram/test_dataloader.png)
_`pin_memory=True`指示Dataloader分配共享GPU内存来加载数据集_

### **`.to('cuda')`**的显存分配
这里与`cudaMalloc`的行为一样，优先分配专用GPU内存，然后分配共享GPU内存。  

```python
import torch
import sys

# 假设您的显卡是 16GB
# 我们将尝试分配一个 18GB 的张量
# 18 GB = 18 * 1024 * 1024 * 1024 字节
GB_TO_ALLOCATE = 48 
bytes_to_allocate = GB_TO_ALLOCATE * 1024**3

# PyTorch 张量通常是 float32 (4 字节)
# 我们需要分配 (bytes_to_allocate / 4) 个元素
num_elements = bytes_to_allocate // 4

if not torch.cuda.is_available():
    print("错误：找不到 CUDA 设备。无法执行此实验。")
    sys.exit()

print(f"CUDA 设备: {torch.cuda.get_device_name(0)}")

# 1. 打印您当前的显存情况
total_vram_bytes = torch.cuda.get_device_properties(0).total_memory
free_vram_bytes, _ = torch.cuda.mem_get_info()
print(f"总显存 (Total VRAM，专用GPU内存):   {total_vram_bytes / 1024**3:.2f} GB")
print(f"当前可用 (Free VRAM，专用GPU内存): {free_vram_bytes / 1024**3:.2f} GB")
print("---")
print(f"实验目标：尝试分配一个 {GB_TO_ALLOCATE} GB 的张量到GPU内存...")
print(f"(这需要 {num_elements} 个 float32 元素)")
print("---")
print("按 Enter 键开始尝试分配... (这应该会报错)")
input()

# 2. 尝试分配超大张量
try:
    print("正在尝试分配...")
    # torch.empty 会尝试分配内存，但不会初始化
    # .to('cuda') 是关键步骤，它指示 PyTorch 在 GPU 上分配
    large_tensor = torch.empty(num_elements, dtype=torch.float32).to('cuda')
    
    # 如果代码能运行到这里，说明您有超过 18GB 的 VRAM
    print("\n!!! 实验意外：分配成功了！!!!")
    print(f"这说明您的可用GPU内存大于 {GB_TO_ALLOCATE}GB。")
    print("请尝试在脚本顶部增加 GB_TO_ALLOCATE 的值再试一次。")
    
    # 清理内存
    del large_tensor
    torch.cuda.empty_cache()

except torch.cuda.OutOfMemoryError as e:
    print("\n--- 实验成功：捕获到预期的错误 ---")
    print("这证明了 PyTorch 无法在GPU内存 中找到足够的连续空间。")
    print("\n错误详情:")
    print(f"错误类型: {type(e)}")
    print(f"错误信息: {e}")
    print("\n--- 实验结束 ---")

except Exception as e:
    print(f"\n发生了意外的错误: {e}")
```
![alt text](assets/img/gpu-vram/test_vram.png)
_这里与`cudaMalloc`的行为一样，优先分配专用GPU内存，然后分配共享GPU内存_